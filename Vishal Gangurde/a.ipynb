import torch
import torch.nn as nn
import torch.optim as optim
from torch_geometric.data import Data, DataLoader
from torch_geometric.nn import GraphConv

# Assuming you have already loaded and pre-processed your data into X_train, y_train, X_test, y_test

# Convert features and target to PyTorch tensors
X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)
X_test_tensor = torch.tensor(X_test, dtype=torch.float32)
y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)

# Convert the edge_index to PyTorch tensor with shape [2, num_edges]
# For simplicity, assuming a fully connected graph, adjust accordingly based on your actual graph structure
num_nodes = X_train_tensor.shape[0]
edge_index_tensor = torch.tensor([
    [i for i in range(num_nodes) for _ in range(num_nodes)],
    [j for _ in range(num_nodes) for j in range(num_nodes)]
], dtype=torch.long)

# Define a simple GNN model using GraphConv layers
class GNNModel(nn.Module):
    def __init__(self, input_size):
        super(GNNModel, self).__init__()
        self.conv1 = GraphConv(input_size, 16)
        self.conv2 = GraphConv(16, 1)

    def forward(self, x, edge_index):
        x = torch.relu(self.conv1(x, edge_index))
        x = torch.relu(self.conv2(x, edge_index))
        return x

# Create a GNN model
input_size = X_train_tensor.shape[1]
model = GNNModel(input_size)

# Define loss function and optimizer
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Convert data to PyTorch Geometric Data objects
train_data = Data(x=X_train_tensor, edge_index=edge_index_tensor, y=y_train_tensor)
test_data = Data(x=X_test_tensor, edge_index=edge_index_tensor, y=y_test_tensor)

# Define data loaders
train_loader = DataLoader([train_data], batch_size=64, shuffle=True)
test_loader = DataLoader([test_data], batch_size=64, shuffle=False)

# Training loop
epochs = 10
for epoch in range(epochs):
    model.train()
    for batch in train_loader:
        optimizer.zero_grad()
        out = model(batch.x, batch.edge_index)
        loss = criterion(out, batch.y.view(-1, 1))
        loss.backward()
        optimizer.step()

# Evaluation
model.eval()
with torch.no_grad():
    for batch in test_loader:
        predictions = model(batch.x, batch.edge_index)
        test_loss = criterion(predictions, batch.y.view(-1, 1))

print("Test Loss:", test_loss.item())
